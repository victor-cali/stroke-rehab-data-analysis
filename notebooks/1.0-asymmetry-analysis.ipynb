{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Stroke Rehab EEG Analysis Pipeline\n",
    "\n",
    "\n",
    "\n",
    " Pipeline to convert .mat files into MNE Raw and Epochs objects and store them in a structured DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üß∞ Setups and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from joblib import cpu_count, Memory\n",
    "import re\n",
    "import mne\n",
    "from mne_features.feature_extraction import FeatureExtractor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Set MNE logging level to WARNING to reduce output verbosity\n",
    "mne.set_log_level(\"WARNING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‚öôÔ∏è Constants Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Dev/stroke-rehab-data-analysis/data/stroke-rehab'\n",
    "FILE_REGEX = r'(?P<subject>P\\d+)_(?P<stage>pre|post)_(?P<split>training|test)\\.mat'\n",
    "CHANNEL_NAMES = ['FC3','FCz','FC4','C5','C3','C1','Cz','C2','C4','C6', 'CP3','CP1','CPz','CP2','CP4','Pz']\n",
    "CHANNEL_TYPES = ['eeg'] * len(CHANNEL_NAMES)\n",
    "MONTAGE = 'standard_1020'\n",
    "EVENT_ID={'left': 1, 'right': 2}\n",
    "N_CORES = 8\n",
    "output_csv_path='laterality_results.csv'\n",
    "# Cache directory to speed up computations\n",
    "cache_path = \"/Dev/stroke-rehab-data-analysis/cache\"\n",
    "memory = Memory(location=cache_path, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'left', 2: 'right'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INVERSE_EVENT_ID = {v: k for k, v in EVENT_ID.items()}\n",
    "INVERSE_EVENT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üìÇ Data File Paths Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "stage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "c779af96-ebf4-4c83-8f68-e68bd71fa06e",
       "rows": [
        [
         "0",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P2_post_training.mat",
         "P2",
         "post",
         "training"
        ],
        [
         "1",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P2_post_test.mat",
         "P2",
         "post",
         "test"
        ],
        [
         "2",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P2_pre_training.mat",
         "P2",
         "pre",
         "training"
        ],
        [
         "3",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P3_pre_training.mat",
         "P3",
         "pre",
         "training"
        ],
        [
         "4",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P1_post_test.mat",
         "P1",
         "post",
         "test"
        ],
        [
         "5",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P3_post_training.mat",
         "P3",
         "post",
         "training"
        ],
        [
         "6",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P1_post_training.mat",
         "P1",
         "post",
         "training"
        ],
        [
         "7",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P3_post_test.mat",
         "P3",
         "post",
         "test"
        ],
        [
         "8",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P1_pre_test.mat",
         "P1",
         "pre",
         "test"
        ],
        [
         "9",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P2_pre_test.mat",
         "P2",
         "pre",
         "test"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>subject</th>\n",
       "      <th>stage</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath subject stage     split\n",
       "0  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P2  post  training\n",
       "1  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P2  post      test\n",
       "2  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P2   pre  training\n",
       "3  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P3   pre  training\n",
       "4  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P1  post      test\n",
       "5  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P3  post  training\n",
       "6  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P1  post  training\n",
       "7  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P3  post      test\n",
       "8  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P1   pre      test\n",
       "9  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P2   pre      test"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_entries = []\n",
    "\n",
    "for fname in os.listdir(DATA_DIR):\n",
    "    match = re.match(FILE_REGEX, fname)\n",
    "    if match:\n",
    "        file_entries.append({\n",
    "            'filepath': os.path.join(DATA_DIR, fname),\n",
    "            'subject': match.group('subject'),\n",
    "            'stage': match.group('stage'),\n",
    "            'split': match.group('split'),\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(file_entries)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üß† MNE Raw Objects Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_info(subject: str, stage: str, split: str, fs: float) -> mne.Info:\n",
    "    \"\"\"\n",
    "    Create an MNE Info object with metadata.\n",
    "\n",
    "    Parameters:\n",
    "    - subject (str): Subject identifier (e.g., 'P1').\n",
    "    - stage (str): Stage of the experiment (e.g., 'pre' or 'post').\n",
    "    - split (str): Data split type (e.g., 'training' or 'test').\n",
    "    - fs (float): Sampling frequency of the data.\n",
    "\n",
    "    Returns:\n",
    "    - mne.Info: MNE Info object containing channel information, montage, and metadata.\n",
    "    \"\"\"\n",
    "    info = mne.create_info(\n",
    "        ch_names=CHANNEL_NAMES,\n",
    "        ch_types=CHANNEL_TYPES,\n",
    "        sfreq=fs\n",
    "    )\n",
    "    info.set_montage(MONTAGE)\n",
    "\n",
    "    # Add metadata\n",
    "    info['subject_info'] = {'his_id': subject}\n",
    "    info['description'] = json.dumps({'stage': stage, 'split': split})\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_annotations(triggers: np.ndarray, fs: float) -> mne.Annotations:\n",
    "    \"\"\"\n",
    "    Create MNE Annotations for the raw data based on trigger events.\n",
    "\n",
    "    Parameters:\n",
    "    - triggers (np.ndarray): Array of trigger values indicating event types.\n",
    "    - fs (float): Sampling frequency of the data.\n",
    "\n",
    "    Returns:\n",
    "    - mne.Annotations: Annotations object containing event onsets, durations, and descriptions.\n",
    "    \"\"\"\n",
    "    # Pad triggers to detect changes at the boundaries\n",
    "    padded = np.r_[0, triggers, 0]\n",
    "    diffs = np.diff(padded)\n",
    "    idx = np.where(diffs != 0)[0]\n",
    "    onsets, offsets = idx[::2], idx[1::2]\n",
    "    values = triggers[onsets]\n",
    "\n",
    "    # Calculate onset times and durations\n",
    "    onset_times = onsets / fs\n",
    "    annot_durations = (offsets - onsets) / fs\n",
    "    annot_descriptions = ['left' if val == 1 else 'right' for val in values]\n",
    "\n",
    "    # Create and return the Annotations object\n",
    "    annot = mne.Annotations(\n",
    "        onset=onset_times,\n",
    "        duration=annot_durations,\n",
    "        description=annot_descriptions\n",
    "    )\n",
    "    return annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_from_mat(filepath: str, subject: str, stage: str, split: str) -> mne.io.Raw:\n",
    "    \"\"\"\n",
    "    Load raw EEG data from a .mat file and return an MNE Raw object.\n",
    "\n",
    "    Parameters:\n",
    "    - filepath (str): Path to the .mat file.\n",
    "    - subject (str): Subject identifier (e.g., 'P1').\n",
    "    - stage (str): Experiment stage (e.g., 'pre' or 'post').\n",
    "    - split (str): Data split type (e.g., 'training' or 'test').\n",
    "\n",
    "    Returns:\n",
    "    - mne.io.Raw: MNE Raw object containing EEG data and annotations.\n",
    "    \"\"\"\n",
    "    mat: dict = loadmat(filepath)\n",
    "    data: np.ndarray = mat['y'].T\n",
    "    triggers: np.ndarray = mat['trig'].ravel()\n",
    "    fs: float = float(mat['fs'].squeeze())\n",
    "    \n",
    "    info: mne.Info = make_info(subject, stage, split, fs)\n",
    "    raw: mne.io.Raw = mne.io.RawArray(data, info)\n",
    "\n",
    "    annot: mne.Annotations = make_annotations(triggers, fs)\n",
    "    raw.set_annotations(annot)\n",
    "    raw = raw.copy().filter(1., 40.)\n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['raw'] = df.apply(\n",
    "    lambda row: load_raw_from_mat(row['filepath'], row['subject'], row['stage'], row['split']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "stage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6775f665-3f1b-498f-b5a6-50a5de42a554",
       "rows": [
        [
         "0",
         "P2",
         "post",
         "training",
         "RawArray"
        ],
        [
         "1",
         "P2",
         "post",
         "test",
         "RawArray"
        ],
        [
         "2",
         "P2",
         "pre",
         "training",
         "RawArray"
        ],
        [
         "3",
         "P3",
         "pre",
         "training",
         "RawArray"
        ],
        [
         "4",
         "P1",
         "post",
         "test",
         "RawArray"
        ],
        [
         "5",
         "P3",
         "post",
         "training",
         "RawArray"
        ],
        [
         "6",
         "P1",
         "post",
         "training",
         "RawArray"
        ],
        [
         "7",
         "P3",
         "post",
         "test",
         "RawArray"
        ],
        [
         "8",
         "P1",
         "pre",
         "test",
         "RawArray"
        ],
        [
         "9",
         "P2",
         "pre",
         "test",
         "RawArray"
        ],
        [
         "10",
         "P1",
         "pre",
         "training",
         "RawArray"
        ],
        [
         "11",
         "P3",
         "pre",
         "test",
         "RawArray"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>stage</th>\n",
       "      <th>split</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject stage     split       raw\n",
       "0       P2  post  training  RawArray\n",
       "1       P2  post      test  RawArray\n",
       "2       P2   pre  training  RawArray\n",
       "3       P3   pre  training  RawArray\n",
       "4       P1  post      test  RawArray\n",
       "5       P3  post  training  RawArray\n",
       "6       P1  post  training  RawArray\n",
       "7       P3  post      test  RawArray\n",
       "8       P1   pre      test  RawArray\n",
       "9       P2   pre      test  RawArray\n",
       "10      P1   pre  training  RawArray\n",
       "11      P3   pre      test  RawArray"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the simple string columns\n",
    "meta = df[[\"subject\", \"stage\", \"split\"]]\n",
    "# Create a new DataFrame with the types of the objects\n",
    "types = df[[\"raw\"]].map(lambda x: type(x).__name__)\n",
    "# Concatenate both for display\n",
    "pd.concat([meta, types], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‚úÇÔ∏è MNE Epochs Objects Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_epochs_from_raw(raw: mne.io.Raw) -> mne.Epochs:\n",
    "    \"\"\"\n",
    "    Create MNE Epochs from a Raw object.\n",
    "\n",
    "    Parameters:\n",
    "    - raw (mne.io.Raw): The MNE Raw object containing EEG data and annotations.\n",
    "\n",
    "    Returns:\n",
    "    - mne.Epochs: The MNE Epochs object created from the raw data.\n",
    "    \"\"\"\n",
    "    fs: float = raw.info['sfreq']\n",
    "    events, event_id = mne.events_from_annotations(raw, event_id=EVENT_ID)\n",
    "    events[:, 0] += int(2 * fs)  # Shift events forward by 2 seconds as per task description\n",
    "\n",
    "    metadata = [json.loads(raw.info['description'])]*events.shape[0]\n",
    "    metadata_df = pd.DataFrame(metadata)\n",
    "    \n",
    "    epochs: mne.Epochs = mne.Epochs(raw, events, tmin=-1.5, tmax=6.0, event_id=event_id, metadata=metadata_df, baseline=(-1.5, 0), preload=True)\n",
    "    \n",
    "    return epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['epochs'] = df['raw'].apply(create_epochs_from_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üßæ Final DataFrame Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "stage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "epochs",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "49a47fad-0470-4481-be95-a25edd251889",
       "rows": [
        [
         "0",
         "P2",
         "post",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "1",
         "P2",
         "post",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "2",
         "P2",
         "pre",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "3",
         "P3",
         "pre",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "4",
         "P1",
         "post",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "5",
         "P3",
         "post",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "6",
         "P1",
         "post",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "7",
         "P3",
         "post",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "8",
         "P1",
         "pre",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "9",
         "P2",
         "pre",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "10",
         "P1",
         "pre",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "11",
         "P3",
         "pre",
         "test",
         "RawArray",
         "Epochs"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>stage</th>\n",
       "      <th>split</th>\n",
       "      <th>raw</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject stage     split       raw  epochs\n",
       "0       P2  post  training  RawArray  Epochs\n",
       "1       P2  post      test  RawArray  Epochs\n",
       "2       P2   pre  training  RawArray  Epochs\n",
       "3       P3   pre  training  RawArray  Epochs\n",
       "4       P1  post      test  RawArray  Epochs\n",
       "5       P3  post  training  RawArray  Epochs\n",
       "6       P1  post  training  RawArray  Epochs\n",
       "7       P3  post      test  RawArray  Epochs\n",
       "8       P1   pre      test  RawArray  Epochs\n",
       "9       P2   pre      test  RawArray  Epochs\n",
       "10      P1   pre  training  RawArray  Epochs\n",
       "11      P3   pre      test  RawArray  Epochs"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the simple string columns\n",
    "meta = df[[\"subject\", \"stage\", \"split\"]]\n",
    "# Create a new DataFrame with the types of the objects\n",
    "types = df[[\"raw\",\"epochs\"]].map(lambda x: type(x).__name__)\n",
    "# Concatenate both for display\n",
    "pd.concat([meta, types], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laterality Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from mne_features.feature_extraction import FeatureExtractor\n",
    "\n",
    "def calculate_batch_laterality_coefficients(epochs, active_time=(2.0, 6.0), baseline_time=(-1.5, 0)):\n",
    "    \"\"\"\n",
    "    Calculate laterality coefficients for multiple epochs and events efficiently.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    epochs : mne.Epochs\n",
    "        The epochs object containing EEG data.\n",
    "    freq_band : tuple, optional\n",
    "        The frequency band of interest (default: mu rhythm 8-13 Hz).\n",
    "    active_time : tuple, optional\n",
    "        Time window for calculating ERD/ERS (default: 2 to 6 seconds post-stimulus).\n",
    "    baseline_time : tuple, optional\n",
    "        Time window for baseline (default: -1.5 to 0 seconds pre-stimulus).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pandas.DataFrame\n",
    "        DataFrame containing the laterality coefficients and associated metadata.\n",
    "    \"\"\"\n",
    "    \n",
    "    reverse_mapping = {v: k for k, v in epochs.event_id.items()}\n",
    "    events_list = [reverse_mapping[num] for num in epochs.events[:, 2]]\n",
    "    \n",
    "    # Ensure we have C3 and C4 channels\n",
    "    if 'C3' not in epochs.ch_names or 'C4' not in epochs.ch_names:\n",
    "        raise ValueError(\"Channels C3 and C4 must be present in the data\")\n",
    "    \n",
    "    # Extract baseline epochs\n",
    "    baseline_epochs = epochs.copy().crop(tmin=baseline_time[0], tmax=baseline_time[1])\n",
    "    \n",
    "    # Extract active epochs\n",
    "    active_epochs = epochs.copy().crop(tmin=active_time[0], tmax=active_time[1])\n",
    "    \n",
    "    freq_bands = {f'mu_band': (12.0, 30.0)}\n",
    "    selected_funcs = ['pow_freq_bands']\n",
    "    feature_extractor = FeatureExtractor(\n",
    "        sfreq=epochs.info['sfreq'], \n",
    "        selected_funcs=selected_funcs, \n",
    "        params={'pow_freq_bands__freq_bands': freq_bands},\n",
    "        n_jobs=N_CORES,\n",
    "        memory=cache_path\n",
    "    )\n",
    "    \n",
    "    # Extract features\n",
    "    baseline_features = feature_extractor.fit_transform(baseline_epochs.pick(('C3','C4')).get_data())\n",
    "    active_features = feature_extractor.fit_transform(active_epochs.pick(('C3','C4')).get_data())\n",
    "    c3_idx, c4_idx = 0, 1\n",
    "    \n",
    "    # Calculate ERD/ERS for each epoch\n",
    "    # ERD/ERS = (active - baseline) / baseline\n",
    "    erd_ers_c3 = (active_features[:, c3_idx] - baseline_features[:, c3_idx]) / baseline_features[:, c3_idx]\n",
    "    erd_ers_c4 = (active_features[:, c4_idx] - baseline_features[:, c4_idx]) / baseline_features[:, c4_idx]\n",
    "    \n",
    "    # Initialize results list\n",
    "    results = []\n",
    "    \n",
    "    # Calculate laterality coefficient for each epoch\n",
    "    for i, event in enumerate(events_list):\n",
    "        # Determine contralateral and ipsilateral hemispheres based on hand movement\n",
    "        if event == 'right':\n",
    "            # Left hemisphere (C3) is contralateral to right hand\n",
    "            contralateral_value = erd_ers_c3[i]\n",
    "            ipsilateral_value = erd_ers_c4[i]\n",
    "        elif event == 'left':\n",
    "            # Right hemisphere (C4) is contralateral to left hand\n",
    "            contralateral_value = erd_ers_c4[i]\n",
    "            ipsilateral_value = erd_ers_c3[i]\n",
    "        \n",
    "        # Calculate laterality coefficient\n",
    "        # Handle potential division by zero or NaN values\n",
    "        try:\n",
    "            lc = (contralateral_value - ipsilateral_value) / (contralateral_value + ipsilateral_value)\n",
    "            # Check if result is valid\n",
    "            if np.isnan(lc) or np.isinf(lc):\n",
    "                lc = np.nan\n",
    "        except:\n",
    "            lc = np.nan\n",
    "        \n",
    "        # Add result to list\n",
    "        results.append({\n",
    "            'event': event,\n",
    "            'LC': lc\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[  1.926984, ..., -12.046854],\n",
      "        [ -2.238482, ...,  -1.16459 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 26.397892, ..., -16.178039],\n",
      "        [ 41.140413, ...,  -1.04856 ]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________extract_features - 7.9s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ 2.689796e+00, ..., -1.034258e+01],\n",
      "        [ 1.000137e+01, ..., -6.330864e-01]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 1.087992e+01, ..., -1.456479e+01],\n",
      "        [-1.228467e+01, ...,  2.732258e-03]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ 12.380537, ...,  -8.208964],\n",
      "        [ 13.312631, ...,  -5.272901]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 54.934079, ..., -36.00186 ],\n",
      "        [ 24.384336, ...,  14.685908]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[-30.036458, ...,  37.536179],\n",
      "        [-21.33882 , ...,  16.149198]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-38.169662, ..., -35.177987],\n",
      "        [-14.709093, ..., -18.912556]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ -9.6438  , ..., -10.061781],\n",
      "        [  4.031585, ...,  -1.798987]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-18.082443, ...,  60.430842],\n",
      "        [-26.639011, ..., -14.840758]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[-15.782339, ..., -24.329428],\n",
      "        [ 19.96037 , ..., -25.823529]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  4.679515, ..., -63.333373],\n",
      "        [  2.758633, ..., -85.926049]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ -8.904488, ..., -29.300935],\n",
      "        [ -0.594822, ..., -11.515533]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 37.48605 , ...,   2.983587],\n",
      "        [ 92.084117, ...,   7.441921]]], shape=(79, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ -8.657787, ...,  -9.52737 ],\n",
      "        [ 10.542079, ..., -16.951507]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  2.0107  , ...,  -0.260631],\n",
      "        [ -6.935195, ..., -29.437813]]], shape=(79, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ -5.324579, ...,   8.347768],\n",
      "        [ -7.484405, ...,   2.629788]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 23.309811, ..., -11.197988],\n",
      "        [  7.076086, ...,   2.112308]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ -4.958386, ..., -10.947345],\n",
      "        [ -3.551196, ..., -20.680875]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ -8.942734, ...,  -0.798005],\n",
      "        [ -4.465446, ...,  -0.220047]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ -5.136805, ...,  71.574145],\n",
      "        [  2.883673, ...,  31.003416]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  3.706842, ..., -18.734044],\n",
      "        [  4.333286, ..., -29.12726 ]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[-22.171818, ...,  -6.05974 ],\n",
      "        [-16.176054, ...,   2.349868]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-41.73748 , ...,   5.143088],\n",
      "        [-23.924655, ...,  29.478647]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ 27.740824, ...,   1.561487],\n",
      "        [ 15.65672 , ...,   0.113559]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-14.583527, ...,  11.445971],\n",
      "        [-15.639918, ...,   1.323689]]], shape=(79, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[  4.904909, ...,  -4.219673],\n",
      "        [  0.176528, ...,  11.024998]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  9.60367 , ..., -12.175036],\n",
      "        [  0.451449, ..., -12.84704 ]]], shape=(79, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ 32.341789, ...,  33.350945],\n",
      "        [ 13.776768, ...,  17.725562]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  4.17392 , ...,  17.060269],\n",
      "        [-17.15361 , ...,   6.555538]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ 34.380523, ...,  -5.966637],\n",
      "        [ 10.2025  , ...,   6.007621]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 32.477485, ...,  13.539624],\n",
      "        [  8.350867, ..., -18.437611]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ -0.206996, ...,  -5.289256],\n",
      "        [ -2.919889, ...,   2.081211]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-48.818133, ..., -25.148753],\n",
      "        [-26.552548, ..., -23.606715]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ -1.226327, ...,  -3.169769],\n",
      "        [  2.202984, ...,  -5.201092]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-31.388646, ...,  -9.306527],\n",
      "        [-28.293706, ...,   1.078478]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ 71.447377, ...,   1.08649 ],\n",
      "        [ 48.609473, ...,  10.812031]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ -8.043142, ..., -20.758496],\n",
      "        [  2.636756, ..., -21.079063]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[  9.060071, ..., -38.1233  ],\n",
      "        [  8.44291 , ..., -27.534148]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  9.008379, ..., -37.356497],\n",
      "        [  1.042977, ...,  24.224399]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[-4.132248, ...,  1.955697],\n",
      "        [-8.98243 , ..., 12.048466]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[12.911796, ...,  0.226373],\n",
      "        [12.745037, ..., -4.851912]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[-11.928531, ...,  -9.403867],\n",
      "        [-14.825149, ...,  -7.547899]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 12.258171, ...,   3.829687],\n",
      "        [ -3.110188, ...,   3.79183 ]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ -2.218169, ...,  33.614133],\n",
      "        [-13.498838, ...,  39.340348]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 11.295376, ...,  -2.076572],\n",
      "        [ 14.194471, ...,   3.346928]]], shape=(79, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[-3.728602, ..., 20.25196 ],\n",
      "        [ 7.093707, ..., 39.871865]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[55.18912 , ..., 22.139849],\n",
      "        [18.265371, ..., -5.941633]]], shape=(79, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (12.0, 30.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "csv_path = 'laterality_results.csv'\n",
    "results = []\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "file_exists = os.path.exists(csv_path)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    subject_id = row['subject']\n",
    "    stage = row['stage']\n",
    "    split = row['split']\n",
    "    epochs = row['epochs']\n",
    "    \n",
    "    # Compute LC DataFrame\n",
    "    lc_df = calculate_batch_laterality_coefficients(epochs)\n",
    "    \n",
    "    # Add metadata\n",
    "    lc_df['subject'] = subject_id\n",
    "    lc_df['stage'] = stage\n",
    "    lc_df['split'] = split\n",
    "    \n",
    "    # Reorder columns\n",
    "    lc_df = lc_df[['subject', 'stage', 'split', 'event', 'LC']]\n",
    "    \n",
    "    # Append to CSV\n",
    "    lc_df.to_csv(csv_path, mode='a', index=False, header=not file_exists)\n",
    "    \n",
    "    # After first write, set file_exists to True\n",
    "    file_exists = True\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep_stage_classification_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

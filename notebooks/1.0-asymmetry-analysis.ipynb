{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Stroke Rehab EEG Analysis Pipeline\n",
    "\n",
    "\n",
    "\n",
    " Pipeline to convert .mat files into MNE Raw and Epochs objects and store them in a structured DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üß∞ Setups and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from joblib import cpu_count, Memory\n",
    "import re\n",
    "import mne\n",
    "from mne_features.feature_extraction import FeatureExtractor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Set MNE logging level to WARNING to reduce output verbosity\n",
    "mne.set_log_level(\"WARNING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‚öôÔ∏è Constants Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Dev/stroke-rehab-data-analysis/data/stroke-rehab'\n",
    "FILE_REGEX = r'(?P<subject>P\\d+)_(?P<stage>pre|post)_(?P<split>training|test)\\.mat'\n",
    "CHANNEL_NAMES = ['FC3','FCz','FC4','C5','C3','C1','Cz','C2','C4','C6', 'CP3','CP1','CPz','CP2','CP4','Pz']\n",
    "CHANNEL_TYPES = ['eeg'] * len(CHANNEL_NAMES)\n",
    "MONTAGE = 'standard_1020'\n",
    "EVENT_ID={'left': 1, 'right': 2}\n",
    "N_CORES = 8\n",
    "output_csv_path='laterality_results.csv'\n",
    "# Cache directory to speed up computations\n",
    "cache_path = \"/Dev/stroke-rehab-data-analysis/cache\"\n",
    "memory = Memory(location=cache_path, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'left', 2: 'right'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INVERSE_EVENT_ID = {v: k for k, v in EVENT_ID.items()}\n",
    "INVERSE_EVENT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üìÇ Data File Paths Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "stage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "fee97c4a-7178-489a-9996-81a1ae907ced",
       "rows": [
        [
         "0",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P2_post_training.mat",
         "P2",
         "post",
         "training"
        ],
        [
         "1",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P2_post_test.mat",
         "P2",
         "post",
         "test"
        ],
        [
         "2",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P2_pre_training.mat",
         "P2",
         "pre",
         "training"
        ],
        [
         "3",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P3_pre_training.mat",
         "P3",
         "pre",
         "training"
        ],
        [
         "4",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P1_post_test.mat",
         "P1",
         "post",
         "test"
        ],
        [
         "5",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P3_post_training.mat",
         "P3",
         "post",
         "training"
        ],
        [
         "6",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P1_post_training.mat",
         "P1",
         "post",
         "training"
        ],
        [
         "7",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P3_post_test.mat",
         "P3",
         "post",
         "test"
        ],
        [
         "8",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P1_pre_test.mat",
         "P1",
         "pre",
         "test"
        ],
        [
         "9",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P2_pre_test.mat",
         "P2",
         "pre",
         "test"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>subject</th>\n",
       "      <th>stage</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath subject stage     split\n",
       "0  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P2  post  training\n",
       "1  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P2  post      test\n",
       "2  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P2   pre  training\n",
       "3  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P3   pre  training\n",
       "4  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P1  post      test\n",
       "5  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P3  post  training\n",
       "6  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P1  post  training\n",
       "7  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P3  post      test\n",
       "8  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P1   pre      test\n",
       "9  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P2   pre      test"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_entries = []\n",
    "\n",
    "for fname in os.listdir(DATA_DIR):\n",
    "    match = re.match(FILE_REGEX, fname)\n",
    "    if match:\n",
    "        file_entries.append({\n",
    "            'filepath': os.path.join(DATA_DIR, fname),\n",
    "            'subject': match.group('subject'),\n",
    "            'stage': match.group('stage'),\n",
    "            'split': match.group('split'),\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(file_entries)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üß† MNE Raw Objects Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_info(subject: str, stage: str, split: str, fs: float) -> mne.Info:\n",
    "    \"\"\"\n",
    "    Create an MNE Info object with metadata.\n",
    "\n",
    "    Parameters:\n",
    "    - subject (str): Subject identifier (e.g., 'P1').\n",
    "    - stage (str): Stage of the experiment (e.g., 'pre' or 'post').\n",
    "    - split (str): Data split type (e.g., 'training' or 'test').\n",
    "    - fs (float): Sampling frequency of the data.\n",
    "\n",
    "    Returns:\n",
    "    - mne.Info: MNE Info object containing channel information, montage, and metadata.\n",
    "    \"\"\"\n",
    "    info = mne.create_info(\n",
    "        ch_names=CHANNEL_NAMES,\n",
    "        ch_types=CHANNEL_TYPES,\n",
    "        sfreq=fs\n",
    "    )\n",
    "    info.set_montage(MONTAGE)\n",
    "\n",
    "    # Add metadata\n",
    "    info['subject_info'] = {'his_id': subject}\n",
    "    info['description'] = json.dumps({'stage': stage, 'split': split})\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_annotations(triggers: np.ndarray, fs: float) -> mne.Annotations:\n",
    "    \"\"\"\n",
    "    Create MNE Annotations for the raw data based on trigger events.\n",
    "\n",
    "    Parameters:\n",
    "    - triggers (np.ndarray): Array of trigger values indicating event types.\n",
    "    - fs (float): Sampling frequency of the data.\n",
    "\n",
    "    Returns:\n",
    "    - mne.Annotations: Annotations object containing event onsets, durations, and descriptions.\n",
    "    \"\"\"\n",
    "    # Pad triggers to detect changes at the boundaries\n",
    "    padded = np.r_[0, triggers, 0]\n",
    "    diffs = np.diff(padded)\n",
    "    idx = np.where(diffs != 0)[0]\n",
    "    onsets, offsets = idx[::2], idx[1::2]\n",
    "    values = triggers[onsets]\n",
    "\n",
    "    # Calculate onset times and durations\n",
    "    onset_times = onsets / fs\n",
    "    annot_durations = (offsets - onsets) / fs\n",
    "    annot_descriptions = ['left' if val == 1 else 'right' for val in values]\n",
    "\n",
    "    # Create and return the Annotations object\n",
    "    annot = mne.Annotations(\n",
    "        onset=onset_times,\n",
    "        duration=annot_durations,\n",
    "        description=annot_descriptions\n",
    "    )\n",
    "    return annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_from_mat(filepath: str, subject: str, stage: str, split: str) -> mne.io.Raw:\n",
    "    \"\"\"\n",
    "    Load raw EEG data from a .mat file and return an MNE Raw object.\n",
    "\n",
    "    Parameters:\n",
    "    - filepath (str): Path to the .mat file.\n",
    "    - subject (str): Subject identifier (e.g., 'P1').\n",
    "    - stage (str): Experiment stage (e.g., 'pre' or 'post').\n",
    "    - split (str): Data split type (e.g., 'training' or 'test').\n",
    "\n",
    "    Returns:\n",
    "    - mne.io.Raw: MNE Raw object containing EEG data and annotations.\n",
    "    \"\"\"\n",
    "    mat: dict = loadmat(filepath)\n",
    "    data: np.ndarray = mat['y'].T\n",
    "    triggers: np.ndarray = mat['trig'].ravel()\n",
    "    fs: float = float(mat['fs'].squeeze())\n",
    "    \n",
    "    info: mne.Info = make_info(subject, stage, split, fs)\n",
    "    raw: mne.io.Raw = mne.io.RawArray(data, info)\n",
    "\n",
    "    annot: mne.Annotations = make_annotations(triggers, fs)\n",
    "    raw.set_annotations(annot)\n",
    "\n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['raw'] = df.apply(\n",
    "    lambda row: load_raw_from_mat(row['filepath'], row['subject'], row['stage'], row['split']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "stage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "2cdd0f3c-5b93-46f6-ab0a-6e5362a91769",
       "rows": [
        [
         "0",
         "P2",
         "post",
         "training",
         "RawArray"
        ],
        [
         "1",
         "P2",
         "post",
         "test",
         "RawArray"
        ],
        [
         "2",
         "P2",
         "pre",
         "training",
         "RawArray"
        ],
        [
         "3",
         "P3",
         "pre",
         "training",
         "RawArray"
        ],
        [
         "4",
         "P1",
         "post",
         "test",
         "RawArray"
        ],
        [
         "5",
         "P3",
         "post",
         "training",
         "RawArray"
        ],
        [
         "6",
         "P1",
         "post",
         "training",
         "RawArray"
        ],
        [
         "7",
         "P3",
         "post",
         "test",
         "RawArray"
        ],
        [
         "8",
         "P1",
         "pre",
         "test",
         "RawArray"
        ],
        [
         "9",
         "P2",
         "pre",
         "test",
         "RawArray"
        ],
        [
         "10",
         "P1",
         "pre",
         "training",
         "RawArray"
        ],
        [
         "11",
         "P3",
         "pre",
         "test",
         "RawArray"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>stage</th>\n",
       "      <th>split</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject stage     split       raw\n",
       "0       P2  post  training  RawArray\n",
       "1       P2  post      test  RawArray\n",
       "2       P2   pre  training  RawArray\n",
       "3       P3   pre  training  RawArray\n",
       "4       P1  post      test  RawArray\n",
       "5       P3  post  training  RawArray\n",
       "6       P1  post  training  RawArray\n",
       "7       P3  post      test  RawArray\n",
       "8       P1   pre      test  RawArray\n",
       "9       P2   pre      test  RawArray\n",
       "10      P1   pre  training  RawArray\n",
       "11      P3   pre      test  RawArray"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the simple string columns\n",
    "meta = df[[\"subject\", \"stage\", \"split\"]]\n",
    "# Create a new DataFrame with the types of the objects\n",
    "types = df[[\"raw\"]].map(lambda x: type(x).__name__)\n",
    "# Concatenate both for display\n",
    "pd.concat([meta, types], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‚úÇÔ∏è MNE Epochs Objects Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_epochs_from_raw(raw: mne.io.Raw) -> mne.Epochs:\n",
    "    \"\"\"\n",
    "    Create MNE Epochs from a Raw object.\n",
    "\n",
    "    Parameters:\n",
    "    - raw (mne.io.Raw): The MNE Raw object containing EEG data and annotations.\n",
    "\n",
    "    Returns:\n",
    "    - mne.Epochs: The MNE Epochs object created from the raw data.\n",
    "    \"\"\"\n",
    "    fs: float = raw.info['sfreq']\n",
    "    events, event_id = mne.events_from_annotations(raw, event_id=EVENT_ID)\n",
    "    events[:, 0] += int(2 * fs)  # Shift events forward by 2 seconds as per task description\n",
    "\n",
    "    metadata = [json.loads(raw.info['description'])]*events.shape[0]\n",
    "    metadata_df = pd.DataFrame(metadata)\n",
    "    \n",
    "    epochs: mne.Epochs = mne.Epochs(raw, events, tmin=-1.5, tmax=6.0, event_id=event_id, metadata=metadata_df, baseline=(-1.5, 0), preload=True)\n",
    "    \n",
    "    return epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['epochs'] = df['raw'].apply(create_epochs_from_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üßæ Final DataFrame Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "stage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "epochs",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "a5347695-e1a7-4f6a-919d-1384ffeeed23",
       "rows": [
        [
         "0",
         "P2",
         "post",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "1",
         "P2",
         "post",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "2",
         "P2",
         "pre",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "3",
         "P3",
         "pre",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "4",
         "P1",
         "post",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "5",
         "P3",
         "post",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "6",
         "P1",
         "post",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "7",
         "P3",
         "post",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "8",
         "P1",
         "pre",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "9",
         "P2",
         "pre",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "10",
         "P1",
         "pre",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "11",
         "P3",
         "pre",
         "test",
         "RawArray",
         "Epochs"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>stage</th>\n",
       "      <th>split</th>\n",
       "      <th>raw</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject stage     split       raw  epochs\n",
       "0       P2  post  training  RawArray  Epochs\n",
       "1       P2  post      test  RawArray  Epochs\n",
       "2       P2   pre  training  RawArray  Epochs\n",
       "3       P3   pre  training  RawArray  Epochs\n",
       "4       P1  post      test  RawArray  Epochs\n",
       "5       P3  post  training  RawArray  Epochs\n",
       "6       P1  post  training  RawArray  Epochs\n",
       "7       P3  post      test  RawArray  Epochs\n",
       "8       P1   pre      test  RawArray  Epochs\n",
       "9       P2   pre      test  RawArray  Epochs\n",
       "10      P1   pre  training  RawArray  Epochs\n",
       "11      P3   pre      test  RawArray  Epochs"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the simple string columns\n",
    "meta = df[[\"subject\", \"stage\", \"split\"]]\n",
    "# Create a new DataFrame with the types of the objects\n",
    "types = df[[\"raw\",\"epochs\"]].map(lambda x: type(x).__name__)\n",
    "# Concatenate both for display\n",
    "pd.concat([meta, types], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laterality Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import mne\n",
    "from mne_features.feature_extraction import FeatureExtractor\n",
    "\n",
    "def calculate_batch_laterality_coefficients(epochs, active_time=(2.0, 6.0), baseline_time=(-1.5, 0)):\n",
    "    \"\"\"\n",
    "    Calculate laterality coefficients for multiple epochs and events efficiently.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    epochs : mne.Epochs\n",
    "        The epochs object containing EEG data.\n",
    "    freq_band : tuple, optional\n",
    "        The frequency band of interest (default: mu rhythm 8-13 Hz).\n",
    "    active_time : tuple, optional\n",
    "        Time window for calculating ERD/ERS (default: 2 to 6 seconds post-stimulus).\n",
    "    baseline_time : tuple, optional\n",
    "        Time window for baseline (default: -1.5 to 0 seconds pre-stimulus).\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    results_df : pandas.DataFrame\n",
    "        DataFrame containing the laterality coefficients and associated metadata.\n",
    "    \"\"\"\n",
    "    \n",
    "    reverse_mapping = {v: k for k, v in epochs.event_id.items()}\n",
    "    events_list = [reverse_mapping[num] for num in epochs.events[:, 2]]\n",
    "    \n",
    "    # Ensure we have C3 and C4 channels\n",
    "    if 'C3' not in epochs.ch_names or 'C4' not in epochs.ch_names:\n",
    "        raise ValueError(\"Channels C3 and C4 must be present in the data\")\n",
    "    \n",
    "    # Extract baseline epochs\n",
    "    baseline_epochs = epochs.copy().crop(tmin=baseline_time[0], tmax=baseline_time[1])\n",
    "    \n",
    "    # Extract active epochs\n",
    "    active_epochs = epochs.copy().crop(tmin=active_time[0], tmax=active_time[1])\n",
    "    \n",
    "    freq_bands = {f'mu_band': (8.0, 13.0)}\n",
    "    selected_funcs = ['pow_freq_bands']\n",
    "    feature_extractor = FeatureExtractor(\n",
    "        sfreq=epochs.info['sfreq'], \n",
    "        selected_funcs=selected_funcs, \n",
    "        params={'pow_freq_bands__freq_bands': freq_bands},\n",
    "        n_jobs=N_CORES,\n",
    "        memory=cache_path\n",
    "    )\n",
    "    \n",
    "    # Extract features\n",
    "    baseline_features = feature_extractor.fit_transform(baseline_epochs.pick(('C3','C4')).get_data())\n",
    "    active_features = feature_extractor.fit_transform(active_epochs.pick(('C3','C4')).get_data())\n",
    "    c3_idx, c4_idx = 0, 1\n",
    "    \n",
    "    # Calculate ERD/ERS for each epoch\n",
    "    # ERD/ERS = (active - baseline) / baseline\n",
    "    erd_ers_c3 = (active_features[:, c3_idx] - baseline_features[:, c3_idx]) / baseline_features[:, c3_idx]\n",
    "    erd_ers_c4 = (active_features[:, c4_idx] - baseline_features[:, c4_idx]) / baseline_features[:, c4_idx]\n",
    "    \n",
    "    # Initialize results list\n",
    "    results = []\n",
    "    \n",
    "    # Calculate laterality coefficient for each epoch\n",
    "    for i, event in enumerate(events_list):\n",
    "        # Determine contralateral and ipsilateral hemispheres based on hand movement\n",
    "        if event == 'right':\n",
    "            # Left hemisphere (C3) is contralateral to right hand\n",
    "            contralateral_value = erd_ers_c3[i]\n",
    "            ipsilateral_value = erd_ers_c4[i]\n",
    "        elif event == 'left':\n",
    "            # Right hemisphere (C4) is contralateral to left hand\n",
    "            contralateral_value = erd_ers_c4[i]\n",
    "            ipsilateral_value = erd_ers_c3[i]\n",
    "        \n",
    "        # Calculate laterality coefficient\n",
    "        # Handle potential division by zero or NaN values\n",
    "        try:\n",
    "            lc = (contralateral_value - ipsilateral_value) / (contralateral_value + ipsilateral_value)\n",
    "            # Check if result is valid\n",
    "            if np.isnan(lc) or np.isinf(lc):\n",
    "                lc = np.nan\n",
    "        except:\n",
    "            lc = np.nan\n",
    "        \n",
    "        # Add result to list\n",
    "        results.append({\n",
    "            'event': event,\n",
    "            'LC': lc\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[  5.241694, ..., -27.677387],\n",
      "        [ -6.65168 , ...,  -0.343422]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 33.314821, ..., -15.910857],\n",
      "        [ 56.859787, ..., -11.434887]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 8.1s, 0.1min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[-69.153068, ..., -78.659858],\n",
      "        [-49.978622, ..., -48.436928]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-27.377867, ...,  39.387838],\n",
      "        [-40.901349, ...,  36.419025]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[  1.479791, ...,  -2.82145 ],\n",
      "        [ 12.014513, ..., -10.208235]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 45.500774, ..., -25.992531],\n",
      "        [ 36.00611 , ...,   3.091448]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[-72.328984, ..., -10.113534],\n",
      "        [-81.53031 , ..., -38.888288]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-46.047631, ..., -34.76899 ],\n",
      "        [-24.732706, ...,  -9.275129]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ 12.102626, ...,  61.11378 ],\n",
      "        [ 68.884326, ..., 102.787493]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-27.843888, ...,  79.700824],\n",
      "        [-14.997304, ..., -13.645072]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[  29.910212, ...,   76.341532],\n",
      "        [  76.598529, ...,  129.055041]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ -51.415837, ..., -108.699407],\n",
      "        [ -85.568929, ..., -151.26618 ]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[  0.672636, ...,  -5.710094],\n",
      "        [ 15.082961, ...,  -2.996955]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 38.752382, ...,  -0.475902],\n",
      "        [120.02911 , ..., -15.563064]]], shape=(79, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ 22.605665, ..., -19.937579],\n",
      "        [ 47.037263, ..., -19.342662]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  4.406308, ...,  29.125996],\n",
      "        [-17.140049, ..., -31.45076 ]]], shape=(79, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ 28.81527 , ...,  19.438317],\n",
      "        [ 15.405839, ...,  -3.340255]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 17.872372, ..., -10.026065],\n",
      "        [  5.326639, ...,   0.883279]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[-100.975746, ...,  -74.698402],\n",
      "        [ -69.973067, ...,  -72.385177]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ -13.678409, ...,   -4.713565],\n",
      "        [ -13.708518, ...,   13.336404]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[  9.195294, ...,  82.209414],\n",
      "        [ 38.722765, ...,  42.036277]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 42.100323, ..., -36.073627],\n",
      "        [ 42.596753, ..., -53.576782]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[-29.328807, ...,   6.464489],\n",
      "        [ -4.380745, ...,  21.085306]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-30.187641, ...,  71.475705],\n",
      "        [-51.362922, ...,  59.141923]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ 27.537018, ..., -10.625091],\n",
      "        [ 15.031098, ...,  -8.787262]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ -6.157163, ...,   7.887759],\n",
      "        [ -8.363555, ...,  -8.984649]]], shape=(79, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[-125.978607, ...,  -99.697357],\n",
      "        [-116.457183, ...,  -33.275543]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ -94.985288, ...,  -74.385679],\n",
      "        [ -69.060821, ...,  -47.695586]]], shape=(79, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ 29.810928, ...,  44.539179],\n",
      "        [  6.16709 , ...,  31.687202]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 19.802211, ...,  22.444552],\n",
      "        [-31.605112, ...,   5.692241]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ 38.970646, ...,  -4.779148],\n",
      "        [ 30.869906, ...,  13.07535 ]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[102.655858, ...,  44.26356 ],\n",
      "        [ -5.946269, ..., -96.180064]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[  -4.958664, ...,   -3.645406],\n",
      "        [  12.358185, ...,    4.535444]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-290.31328 , ...,   75.209769],\n",
      "        [-272.757698, ...,   91.975853]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ 5.242164, ..., -9.879213],\n",
      "        [ 9.342138, ..., -7.818636]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[68.338883, ..., 60.976948],\n",
      "        [58.252483, ..., 32.095424]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[  21.227346, ...,  -52.269548],\n",
      "        [ -50.760304, ..., -101.457829]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  13.224236, ...,  -46.139639],\n",
      "        [  38.673732, ...,   43.134845]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[-47.999231, ..., -64.542971],\n",
      "        [-73.200649, ..., -89.465389]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[-54.641077, ...,   6.366666],\n",
      "        [  3.860986, ...,  45.843273]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[ -9.648273, ..., -17.682026],\n",
      "        [-10.761861, ...,   3.733134]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[  9.873069, ...,   5.566842],\n",
      "        [  3.728208, ..., -10.908741]]], shape=(80, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[-56.793865, ...,  -6.253681],\n",
      "        [-55.691427, ...,  -5.635686]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 10.354095, ..., -22.48114 ],\n",
      "        [-22.694048, ...,  -7.266386]]], shape=(80, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[18.844497, ..., 41.662977],\n",
      "        [-4.217589, ..., 46.422113]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 8.415851, ..., 16.469484],\n",
      "        [24.027654, ..., 13.811239]]], shape=(79, 2, 385)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n",
      "________________________________________________________________________________\n",
      "[Memory] Calling mne_features.feature_extraction.extract_features...\n",
      "extract_features(array([[[-47.0436  , ...,  30.096132],\n",
      "        [-58.671927, ...,  70.998033]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[ 86.530382, ...,  42.629723],\n",
      "        [ 33.987574, ...,  26.546626]]], shape=(79, 2, 1025)), \n",
      "256.0, ['pow_freq_bands'], funcs_params={'pow_freq_bands__freq_bands': {'mu_band': (8.0, 13.0)}}, n_jobs=8)\n",
      "_________________________________________________extract_features - 0.0s, 0.0min\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "csv_path = 'laterality_results.csv'\n",
    "results = []\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "file_exists = os.path.exists(csv_path)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    subject_id = row['subject']\n",
    "    stage = row['stage']\n",
    "    split = row['split']\n",
    "    epochs = row['epochs']\n",
    "    \n",
    "    # Compute LC DataFrame\n",
    "    lc_df = calculate_batch_laterality_coefficients(epochs)\n",
    "    \n",
    "    # Add metadata\n",
    "    lc_df['subject'] = subject_id\n",
    "    lc_df['stage'] = stage\n",
    "    lc_df['split'] = split\n",
    "    \n",
    "    # Reorder columns\n",
    "    lc_df = lc_df[['subject', 'stage', 'split', 'event', 'LC']]\n",
    "    \n",
    "    # Append to CSV\n",
    "    lc_df.to_csv(csv_path, mode='a', index=False, header=not file_exists)\n",
    "    \n",
    "    # After first write, set file_exists to True\n",
    "    file_exists = True\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep_stage_classification_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

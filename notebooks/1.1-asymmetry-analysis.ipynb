{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Stroke Rehab EEG Analysis Pipeline\n",
    "\n",
    "\n",
    "\n",
    " Pipeline to convert .mat files into MNE Raw and Epochs objects and store them in a structured DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üß∞ Setups and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import mne\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‚öôÔ∏è Constants Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './stroke-rehab-data-analysis/data/stroke-rehab'\n",
    "FILE_REGEX = r'(?P<subject>P\\d+)_(?P<stage>pre|post)_(?P<split>training|test)\\.mat'\n",
    "CHANNEL_NAMES = ['FC3','FCz','FC4','C5','C3','C1','Cz','C2','C4','C6', 'CP3','CP1','CPz','CP2','CP4','Pz']\n",
    "CHANNEL_TYPES = ['eeg'] * len(CHANNEL_NAMES)\n",
    "MONTAGE = 'standard_1020'\n",
    "EVENT_ID={'left': 1, 'right': 2}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üìÇ Data File Paths Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>subject</th>\n",
       "      <th>stage</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./stroke-rehab-data-analysis/data/stroke-rehab...</td>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./stroke-rehab-data-analysis/data/stroke-rehab...</td>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./stroke-rehab-data-analysis/data/stroke-rehab...</td>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./stroke-rehab-data-analysis/data/stroke-rehab...</td>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./stroke-rehab-data-analysis/data/stroke-rehab...</td>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./stroke-rehab-data-analysis/data/stroke-rehab...</td>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./stroke-rehab-data-analysis/data/stroke-rehab...</td>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./stroke-rehab-data-analysis/data/stroke-rehab...</td>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./stroke-rehab-data-analysis/data/stroke-rehab...</td>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./stroke-rehab-data-analysis/data/stroke-rehab...</td>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath subject stage     split\n",
       "0  ./stroke-rehab-data-analysis/data/stroke-rehab...      P1  post      test\n",
       "1  ./stroke-rehab-data-analysis/data/stroke-rehab...      P1  post  training\n",
       "2  ./stroke-rehab-data-analysis/data/stroke-rehab...      P1   pre      test\n",
       "3  ./stroke-rehab-data-analysis/data/stroke-rehab...      P1   pre  training\n",
       "4  ./stroke-rehab-data-analysis/data/stroke-rehab...      P2  post      test\n",
       "5  ./stroke-rehab-data-analysis/data/stroke-rehab...      P2  post  training\n",
       "6  ./stroke-rehab-data-analysis/data/stroke-rehab...      P2   pre      test\n",
       "7  ./stroke-rehab-data-analysis/data/stroke-rehab...      P2   pre  training\n",
       "8  ./stroke-rehab-data-analysis/data/stroke-rehab...      P3  post      test\n",
       "9  ./stroke-rehab-data-analysis/data/stroke-rehab...      P3  post  training"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_entries = []\n",
    "\n",
    "for fname in os.listdir(DATA_DIR):\n",
    "    match = re.match(FILE_REGEX, fname)\n",
    "    if match:\n",
    "        file_entries.append({\n",
    "            'filepath': os.path.join(DATA_DIR, fname),\n",
    "            'subject': match.group('subject'),\n",
    "            'stage': match.group('stage'),\n",
    "            'split': match.group('split'),\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(file_entries)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üß† MNE Raw Objects Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_info(subject, stage, split, fs):\n",
    "    \"\"\"Create MNE info object with metadata.\"\"\"\n",
    "    info = mne.create_info(\n",
    "        ch_names=CHANNEL_NAMES,\n",
    "        sfreq=fs,\n",
    "        ch_types=CHANNEL_TYPES\n",
    "    )\n",
    "    info.set_montage(MONTAGE)\n",
    "\n",
    "    # Add metadata\n",
    "    info['subject_info'] = {'his_id': subject}\n",
    "    info['description'] = str({'stage': stage, 'split': split})\n",
    "\n",
    "    return info\n",
    "\n",
    "def make_annotations(triggers, fs):\n",
    "    \"\"\"Create annotations for the raw data.\"\"\"\n",
    "    # Create annotations based on the triggers\n",
    "    padded = np.r_[0, triggers, 0]\n",
    "    diffs = np.diff(padded)\n",
    "    idx = np.where(diffs != 0)[0]\n",
    "    onsets, offsets = idx[::2], idx[1::2]\n",
    "    values = triggers[onsets]\n",
    "\n",
    "    onset_times = onsets / fs\n",
    "    annot_durations = (offsets - onsets) / fs\n",
    "    annot_descriptions = ['left' if val == 1 else 'right' for val in values]\n",
    "\n",
    "    annot = mne.Annotations(onset=onset_times,\n",
    "                            duration=annot_durations,\n",
    "                            description=annot_descriptions)\n",
    "    \n",
    "    return annot\n",
    "\n",
    "def load_raw_from_mat(filepath, subject, stage, split):\n",
    "    \"\"\"Load raw data from .mat file.\"\"\"\n",
    "    mat = loadmat(filepath)\n",
    "    data = mat['y'].T\n",
    "    triggers = mat['trig'].ravel()\n",
    "    fs = float(mat['fs'].squeeze())\n",
    "    \n",
    "    info = make_info(subject, stage, split, fs)\n",
    "\n",
    "    raw = mne.io.RawArray(data, info)\n",
    "\n",
    "    annot = make_annotations(triggers, fs)\n",
    "    \n",
    "    raw.set_annotations(annot)\n",
    "\n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=16, n_times=194088\n",
      "    Range : 0 ... 194087 =      0.000 ...   758.152 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=197343\n",
      "    Range : 0 ... 197342 =      0.000 ...   770.867 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=204560\n",
      "    Range : 0 ... 204559 =      0.000 ...   799.059 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=271816\n",
      "    Range : 0 ... 271815 =      0.000 ...  1061.777 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=233576\n",
      "    Range : 0 ... 233575 =      0.000 ...   912.402 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=216720\n",
      "    Range : 0 ... 216719 =      0.000 ...   846.559 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=199552\n",
      "    Range : 0 ... 199551 =      0.000 ...   779.496 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=223112\n",
      "    Range : 0 ... 223111 =      0.000 ...   871.527 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=218432\n",
      "    Range : 0 ... 218431 =      0.000 ...   853.246 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=206504\n",
      "    Range : 0 ... 206503 =      0.000 ...   806.652 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=248488\n",
      "    Range : 0 ... 248487 =      0.000 ...   970.652 secs\n",
      "Ready.\n",
      "Creating RawArray with float64 data, n_channels=16, n_times=205536\n",
      "    Range : 0 ... 205535 =      0.000 ...   802.871 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "df['raw'] = df.apply(\n",
    "    lambda row: load_raw_from_mat(row['filepath'], row['subject'], row['stage'], row['split']),\n",
    "    axis=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>stage</th>\n",
       "      <th>split</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject stage     split       raw\n",
       "0       P1  post      test  RawArray\n",
       "1       P1  post  training  RawArray\n",
       "2       P1   pre      test  RawArray\n",
       "3       P1   pre  training  RawArray\n",
       "4       P2  post      test  RawArray\n",
       "5       P2  post  training  RawArray\n",
       "6       P2   pre      test  RawArray\n",
       "7       P2   pre  training  RawArray\n",
       "8       P3  post      test  RawArray\n",
       "9       P3  post  training  RawArray\n",
       "10      P3   pre      test  RawArray\n",
       "11      P3   pre  training  RawArray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the simple string columns\n",
    "meta = df[[\"subject\", \"stage\", \"split\"]]\n",
    "# Create a new DataFrame with the types of the objects\n",
    "types = df[[\"raw\"]].map(lambda x: type(x).__name__)\n",
    "# Concatenate both for display\n",
    "pd.concat([meta, types], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‚úÇÔ∏è MNE Epochs Objects Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_epochs_from_raw(raw):\n",
    "    fs = raw.info['sfreq']\n",
    "    events, event_id = mne.events_from_annotations(raw, event_id=EVENT_ID)\n",
    "    events[:, 0] += int(2 * fs)  # Shift events forward 2s per task description\n",
    "    epochs = mne.Epochs(raw, events, event_id=event_id)\n",
    "    return epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: [np.str_('left'), np.str_('right')]\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Setting baseline interval to [-0.19921875, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: [np.str_('left'), np.str_('right')]\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Setting baseline interval to [-0.19921875, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: [np.str_('left'), np.str_('right')]\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Setting baseline interval to [-0.19921875, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: [np.str_('left'), np.str_('right')]\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Setting baseline interval to [-0.19921875, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: [np.str_('left'), np.str_('right')]\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Setting baseline interval to [-0.19921875, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: [np.str_('left'), np.str_('right')]\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Setting baseline interval to [-0.19921875, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: [np.str_('left'), np.str_('right')]\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Setting baseline interval to [-0.19921875, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: [np.str_('left'), np.str_('right')]\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Setting baseline interval to [-0.19921875, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: [np.str_('left'), np.str_('right')]\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Setting baseline interval to [-0.19921875, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: [np.str_('left'), np.str_('right')]\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Setting baseline interval to [-0.19921875, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: [np.str_('left'), np.str_('right')]\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Setting baseline interval to [-0.19921875, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Used Annotations descriptions: [np.str_('left'), np.str_('right')]\n",
      "Not setting metadata\n",
      "80 matching events found\n",
      "Setting baseline interval to [-0.19921875, 0.0] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n"
     ]
    }
   ],
   "source": [
    "df['epochs'] = df['raw'].apply(create_epochs_from_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üßæ Final DataFrame Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>stage</th>\n",
       "      <th>split</th>\n",
       "      <th>raw</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject stage     split       raw  epochs\n",
       "0       P1  post      test  RawArray  Epochs\n",
       "1       P1  post  training  RawArray  Epochs\n",
       "2       P1   pre      test  RawArray  Epochs\n",
       "3       P1   pre  training  RawArray  Epochs\n",
       "4       P2  post      test  RawArray  Epochs\n",
       "5       P2  post  training  RawArray  Epochs\n",
       "6       P2   pre      test  RawArray  Epochs\n",
       "7       P2   pre  training  RawArray  Epochs\n",
       "8       P3  post      test  RawArray  Epochs\n",
       "9       P3  post  training  RawArray  Epochs\n",
       "10      P3   pre      test  RawArray  Epochs\n",
       "11      P3   pre  training  RawArray  Epochs"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the simple string columns\n",
    "meta = df[[\"subject\", \"stage\", \"split\"]]\n",
    "# Create a new DataFrame with the types of the objects\n",
    "types = df[[\"raw\",\"epochs\"]].map(lambda x: type(x).__name__)\n",
    "# Concatenate both for display\n",
    "pd.concat([meta, types], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "raw_list=df['raw'].tolist()\n",
    "raw=raw_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def filtration(raw,l_freq,h_freq):\n",
    "    raw_filtered=raw.copy().filter(l_freq=0.5, h_freq=40.)\n",
    "    return(raw_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 1.000 (s)\n"
     ]
    }
   ],
   "source": [
    "def apply_ica(raw):\n",
    "    ica = ICA(n_components=raw.get_data().shape[0], random_state=42, max_iter='auto')\n",
    "    ica.fit(raw_filt)\n",
    "    return ica\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BLI(raw):\n",
    "    psd, freqs=mne.time_frequency.psd_array_welch(raw.get_data(), sfreq=256,fmin=0.5,fmax=40.,n_fft=256)\n",
    "    psds_band = psd.mean(axis=1) \n",
    "    channel_pairs = [\n",
    "        ('FC3', 'FC4'),\n",
    "        ('C5', 'C6'),\n",
    "        ('C3', 'C4'),\n",
    "        ('C1', 'C2'),\n",
    "        ('CP3', 'CP4'),\n",
    "        ('CP1', 'CP2')\n",
    "    ]\n",
    "    ch_names=raw.info['ch_names']\n",
    "    bsi_vals = []\n",
    "    for ch_left, ch_right in channel_pairs:\n",
    "        if ch_left in ch_names and ch_right in ch_names:\n",
    "            idx_left = ch_names.index(ch_left)\n",
    "            idx_right = ch_names.index(ch_right)\n",
    "            P_left = psds_band[idx_left]\n",
    "            P_right = psds_band[idx_right]\n",
    "            denom = P_left + P_right\n",
    "            if denom > 0:\n",
    "                bsi = abs(P_left - P_right) / denom\n",
    "                bsi_vals.append(bsi)\n",
    "    return(bsi_vals)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

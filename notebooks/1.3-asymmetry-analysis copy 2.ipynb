{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Stroke Rehab EEG Analysis Pipeline\n",
    "\n",
    "\n",
    "\n",
    " Pipeline to convert .mat files into MNE Raw and Epochs objects and store them in a structured DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üß∞ Setups and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from joblib import cpu_count, Memory\n",
    "import re\n",
    "import mne\n",
    "from mne_features.feature_extraction import FeatureExtractor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "\n",
    "# Set MNE logging level to WARNING to reduce output verbosity\n",
    "mne.set_log_level(\"WARNING\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‚öôÔ∏è Constants Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = '/Dev/stroke-rehab-data-analysis/data/stroke-rehab'\n",
    "FILE_REGEX = r'(?P<subject>P\\d+)_(?P<stage>pre|post)_(?P<split>training|test)\\.mat'\n",
    "CHANNEL_NAMES = ['FC3','FCz','FC4','C5','C3','C1','Cz','C2','C4','C6', 'CP3','CP1','CPz','CP2','CP4','Pz']\n",
    "CHANNEL_TYPES = ['eeg'] * len(CHANNEL_NAMES)\n",
    "MONTAGE = 'standard_1020'\n",
    "EVENT_ID={'left': 1, 'right': 2}\n",
    "N_CORES = 8\n",
    "output_csv_path='laterality_results.csv'\n",
    "# Cache directory to speed up computations\n",
    "cache_path = \"/Dev/stroke-rehab-data-analysis/cache\"\n",
    "memory = Memory(location=cache_path, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'left', 2: 'right'}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INVERSE_EVENT_ID = {v: k for k, v in EVENT_ID.items()}\n",
    "INVERSE_EVENT_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üìÇ Data File Paths Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "filepath",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "stage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "3e130fc9-1f0e-4368-863b-92724092d527",
       "rows": [
        [
         "0",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P2_post_training.mat",
         "P2",
         "post",
         "training"
        ],
        [
         "1",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P2_post_test.mat",
         "P2",
         "post",
         "test"
        ],
        [
         "2",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P2_pre_training.mat",
         "P2",
         "pre",
         "training"
        ],
        [
         "3",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P3_pre_training.mat",
         "P3",
         "pre",
         "training"
        ],
        [
         "4",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P1_post_test.mat",
         "P1",
         "post",
         "test"
        ],
        [
         "5",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P3_post_training.mat",
         "P3",
         "post",
         "training"
        ],
        [
         "6",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P1_post_training.mat",
         "P1",
         "post",
         "training"
        ],
        [
         "7",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P3_post_test.mat",
         "P3",
         "post",
         "test"
        ],
        [
         "8",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P1_pre_test.mat",
         "P1",
         "pre",
         "test"
        ],
        [
         "9",
         "/Dev/stroke-rehab-data-analysis/data/stroke-rehab/P2_pre_test.mat",
         "P2",
         "pre",
         "test"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>subject</th>\n",
       "      <th>stage</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>/Dev/stroke-rehab-data-analysis/data/stroke-re...</td>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filepath subject stage     split\n",
       "0  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P2  post  training\n",
       "1  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P2  post      test\n",
       "2  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P2   pre  training\n",
       "3  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P3   pre  training\n",
       "4  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P1  post      test\n",
       "5  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P3  post  training\n",
       "6  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P1  post  training\n",
       "7  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P3  post      test\n",
       "8  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P1   pre      test\n",
       "9  /Dev/stroke-rehab-data-analysis/data/stroke-re...      P2   pre      test"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_entries = []\n",
    "\n",
    "for fname in os.listdir(DATA_DIR):\n",
    "    match = re.match(FILE_REGEX, fname)\n",
    "    if match:\n",
    "        file_entries.append({\n",
    "            'filepath': os.path.join(DATA_DIR, fname),\n",
    "            'subject': match.group('subject'),\n",
    "            'stage': match.group('stage'),\n",
    "            'split': match.group('split'),\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(file_entries)\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üß† MNE Raw Objects Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_info(subject: str, stage: str, split: str, fs: float) -> mne.Info:\n",
    "    \"\"\"\n",
    "    Create an MNE Info object with metadata.\n",
    "\n",
    "    Parameters:\n",
    "    - subject (str): Subject identifier (e.g., 'P1').\n",
    "    - stage (str): Stage of the experiment (e.g., 'pre' or 'post').\n",
    "    - split (str): Data split type (e.g., 'training' or 'test').\n",
    "    - fs (float): Sampling frequency of the data.\n",
    "\n",
    "    Returns:\n",
    "    - mne.Info: MNE Info object containing channel information, montage, and metadata.\n",
    "    \"\"\"\n",
    "    info = mne.create_info(\n",
    "        ch_names=CHANNEL_NAMES,\n",
    "        ch_types=CHANNEL_TYPES,\n",
    "        sfreq=fs\n",
    "    )\n",
    "    info.set_montage(MONTAGE)\n",
    "\n",
    "    # Add metadata\n",
    "    info['subject_info'] = {'his_id': subject}\n",
    "    info['description'] = json.dumps({'stage': stage, 'split': split})\n",
    "\n",
    "    return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_annotations(triggers: np.ndarray, fs: float) -> mne.Annotations:\n",
    "    \"\"\"\n",
    "    Create MNE Annotations for the raw data based on trigger events.\n",
    "\n",
    "    Parameters:\n",
    "    - triggers (np.ndarray): Array of trigger values indicating event types.\n",
    "    - fs (float): Sampling frequency of the data.\n",
    "\n",
    "    Returns:\n",
    "    - mne.Annotations: Annotations object containing event onsets, durations, and descriptions.\n",
    "    \"\"\"\n",
    "    # Pad triggers to detect changes at the boundaries\n",
    "    padded = np.r_[0, triggers, 0]\n",
    "    diffs = np.diff(padded)\n",
    "    idx = np.where(diffs != 0)[0]\n",
    "    onsets, offsets = idx[::2], idx[1::2]\n",
    "    values = triggers[onsets]\n",
    "\n",
    "    # Calculate onset times and durations\n",
    "    onset_times = onsets / fs\n",
    "    annot_durations = (offsets - onsets) / fs\n",
    "    annot_descriptions = ['left' if val == 1 else 'right' for val in values]\n",
    "\n",
    "    # Create and return the Annotations object\n",
    "    annot = mne.Annotations(\n",
    "        onset=onset_times,\n",
    "        duration=annot_durations,\n",
    "        description=annot_descriptions\n",
    "    )\n",
    "    return annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_from_mat(filepath: str, subject: str, stage: str, split: str) -> mne.io.Raw:\n",
    "    \"\"\"\n",
    "    Load raw EEG data from a .mat file and return an MNE Raw object.\n",
    "\n",
    "    Parameters:\n",
    "    - filepath (str): Path to the .mat file.\n",
    "    - subject (str): Subject identifier (e.g., 'P1').\n",
    "    - stage (str): Experiment stage (e.g., 'pre' or 'post').\n",
    "    - split (str): Data split type (e.g., 'training' or 'test').\n",
    "\n",
    "    Returns:\n",
    "    - mne.io.Raw: MNE Raw object containing EEG data and annotations.\n",
    "    \"\"\"\n",
    "    mat: dict = loadmat(filepath)\n",
    "    data: np.ndarray = mat['y'].T\n",
    "    triggers: np.ndarray = mat['trig'].ravel()\n",
    "    fs: float = float(mat['fs'].squeeze())\n",
    "    \n",
    "    info: mne.Info = make_info(subject, stage, split, fs)\n",
    "    raw: mne.io.Raw = mne.io.RawArray(data, info)\n",
    "\n",
    "    annot: mne.Annotations = make_annotations(triggers, fs)\n",
    "    raw.set_annotations(annot)\n",
    "    #raw = raw.copy().filter(1., 40.)\n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['raw'] = df.apply(\n",
    "    lambda row: load_raw_from_mat(row['filepath'], row['subject'], row['stage'], row['split']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "stage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "18435281-e5af-4189-9a46-8a37dda0ad64",
       "rows": [
        [
         "0",
         "P2",
         "post",
         "training",
         "RawArray"
        ],
        [
         "1",
         "P2",
         "post",
         "test",
         "RawArray"
        ],
        [
         "2",
         "P2",
         "pre",
         "training",
         "RawArray"
        ],
        [
         "3",
         "P3",
         "pre",
         "training",
         "RawArray"
        ],
        [
         "4",
         "P1",
         "post",
         "test",
         "RawArray"
        ],
        [
         "5",
         "P3",
         "post",
         "training",
         "RawArray"
        ],
        [
         "6",
         "P1",
         "post",
         "training",
         "RawArray"
        ],
        [
         "7",
         "P3",
         "post",
         "test",
         "RawArray"
        ],
        [
         "8",
         "P1",
         "pre",
         "test",
         "RawArray"
        ],
        [
         "9",
         "P2",
         "pre",
         "test",
         "RawArray"
        ],
        [
         "10",
         "P1",
         "pre",
         "training",
         "RawArray"
        ],
        [
         "11",
         "P3",
         "pre",
         "test",
         "RawArray"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>stage</th>\n",
       "      <th>split</th>\n",
       "      <th>raw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject stage     split       raw\n",
       "0       P2  post  training  RawArray\n",
       "1       P2  post      test  RawArray\n",
       "2       P2   pre  training  RawArray\n",
       "3       P3   pre  training  RawArray\n",
       "4       P1  post      test  RawArray\n",
       "5       P3  post  training  RawArray\n",
       "6       P1  post  training  RawArray\n",
       "7       P3  post      test  RawArray\n",
       "8       P1   pre      test  RawArray\n",
       "9       P2   pre      test  RawArray\n",
       "10      P1   pre  training  RawArray\n",
       "11      P3   pre      test  RawArray"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the simple string columns\n",
    "meta = df[[\"subject\", \"stage\", \"split\"]]\n",
    "# Create a new DataFrame with the types of the objects\n",
    "types = df[[\"raw\"]].map(lambda x: type(x).__name__)\n",
    "# Concatenate both for display\n",
    "pd.concat([meta, types], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ‚úÇÔ∏è MNE Epochs Objects Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_epochs_from_raw(raw: mne.io.Raw) -> mne.Epochs:\n",
    "    \"\"\"\n",
    "    Create MNE Epochs from a Raw object.\n",
    "\n",
    "    Parameters:\n",
    "    - raw (mne.io.Raw): The MNE Raw object containing EEG data and annotations.\n",
    "\n",
    "    Returns:\n",
    "    - mne.Epochs: The MNE Epochs object created from the raw data.\n",
    "    \"\"\"\n",
    "    fs: float = raw.info['sfreq']\n",
    "    events, event_id = mne.events_from_annotations(raw, event_id=EVENT_ID)\n",
    "    events[:, 0] += int(2 * fs)  # Shift events forward by 2 seconds as per task description\n",
    "\n",
    "    metadata = [json.loads(raw.info['description'])]*events.shape[0]\n",
    "    metadata_df = pd.DataFrame(metadata)\n",
    "    \n",
    "    epochs: mne.Epochs = mne.Epochs(raw, events, tmin=-1.5, tmax=6.0, event_id=event_id, metadata=metadata_df, baseline=(-1.5, 0), preload=True)\n",
    "    \n",
    "    return epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['epochs'] = df['raw'].apply(create_epochs_from_raw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üßæ Final DataFrame Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "subject",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "stage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "split",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "raw",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "epochs",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "8c68e104-9651-4190-be05-2c1c36f440ea",
       "rows": [
        [
         "0",
         "P2",
         "post",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "1",
         "P2",
         "post",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "2",
         "P2",
         "pre",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "3",
         "P3",
         "pre",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "4",
         "P1",
         "post",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "5",
         "P3",
         "post",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "6",
         "P1",
         "post",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "7",
         "P3",
         "post",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "8",
         "P1",
         "pre",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "9",
         "P2",
         "pre",
         "test",
         "RawArray",
         "Epochs"
        ],
        [
         "10",
         "P1",
         "pre",
         "training",
         "RawArray",
         "Epochs"
        ],
        [
         "11",
         "P3",
         "pre",
         "test",
         "RawArray",
         "Epochs"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 12
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>stage</th>\n",
       "      <th>split</th>\n",
       "      <th>raw</th>\n",
       "      <th>epochs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P2</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>P1</td>\n",
       "      <td>post</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>P3</td>\n",
       "      <td>post</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>P2</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>P1</td>\n",
       "      <td>pre</td>\n",
       "      <td>training</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P3</td>\n",
       "      <td>pre</td>\n",
       "      <td>test</td>\n",
       "      <td>RawArray</td>\n",
       "      <td>Epochs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject stage     split       raw  epochs\n",
       "0       P2  post  training  RawArray  Epochs\n",
       "1       P2  post      test  RawArray  Epochs\n",
       "2       P2   pre  training  RawArray  Epochs\n",
       "3       P3   pre  training  RawArray  Epochs\n",
       "4       P1  post      test  RawArray  Epochs\n",
       "5       P3  post  training  RawArray  Epochs\n",
       "6       P1  post  training  RawArray  Epochs\n",
       "7       P3  post      test  RawArray  Epochs\n",
       "8       P1   pre      test  RawArray  Epochs\n",
       "9       P2   pre      test  RawArray  Epochs\n",
       "10      P1   pre  training  RawArray  Epochs\n",
       "11      P3   pre      test  RawArray  Epochs"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the simple string columns\n",
    "meta = df[[\"subject\", \"stage\", \"split\"]]\n",
    "# Create a new DataFrame with the types of the objects\n",
    "types = df[[\"raw\",\"epochs\"]].map(lambda x: type(x).__name__)\n",
    "# Concatenate both for display\n",
    "pd.concat([meta, types], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laterality Coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mne.decoding import CSP\n",
    "from mne_features.feature_extraction import FeatureExtractor\n",
    "\n",
    "def calculate_batch_laterality_coefficients(epochs, active_time=(2.0, 6.0), baseline_time=(-1.5, 0)):\n",
    "    \"\"\"\n",
    "    Calculate laterality coefficients using the FIRST CSP component\n",
    "    for left vs. right hemispheres, rather than channels C3/C4.\n",
    "    \"\"\"\n",
    "    # map integer events back to names\n",
    "    reverse_mapping = {v: k for k, v in epochs.event_id.items()}\n",
    "    events_list = [reverse_mapping[num] for num in epochs.events[:, 2]]\n",
    "\n",
    "    # define your two hemi channel‚Äësets\n",
    "    left_chs  = ['FC3', 'C5', 'C3', 'C1', 'CP3', 'CP1']\n",
    "    right_chs = ['FC4', 'C6', 'C4', 'C2', 'CP4', 'CP2']\n",
    "\n",
    "    # crop baseline & active windows\n",
    "    baseline_epochs = epochs.copy().crop(tmin=baseline_time[0], tmax=baseline_time[1])\n",
    "    active_epochs   = epochs.copy().crop(tmin=active_time[0], tmax=active_time[1])\n",
    "\n",
    "    # --- 1) Fit CSP on the FULL trial data for each hemisphere ---\n",
    "    labels = epochs.events[:, 2]\n",
    "\n",
    "    # left CSP\n",
    "    left_full = epochs.copy().pick(left_chs).get_data()\n",
    "    csp_left = CSP(n_components=1, transform_into='csp_space')\n",
    "    csp_left.fit(left_full, labels)\n",
    "\n",
    "    # right CSP\n",
    "    right_full = epochs.copy().pick(right_chs).get_data()\n",
    "    csp_right = CSP(n_components=1, transform_into='csp_space')\n",
    "    csp_right.fit(right_full, labels)\n",
    "\n",
    "    # --- 2) Transform baseline & active into CSP space (shape: n_epochs √ó 1 √ó n_times) ---\n",
    "    base_left  = csp_left.transform(baseline_epochs.copy().pick(left_chs).get_data())\n",
    "    act_left   = csp_left.transform(active_epochs.copy().pick(left_chs).get_data())\n",
    "    base_right = csp_right.transform(baseline_epochs.copy().pick(right_chs).get_data())\n",
    "    act_right  = csp_right.transform(active_epochs.copy().pick(right_chs).get_data())\n",
    "\n",
    "    # --- 3) Extract mu‚Äëband power on those 1‚Äëcomponent time series ---\n",
    "    freq_bands = {'mu_band': (7.0, 30.0)}\n",
    "    fx = FeatureExtractor(\n",
    "        sfreq=epochs.info['sfreq'],\n",
    "        selected_funcs=['pow_freq_bands'],\n",
    "        params={'pow_freq_bands__freq_bands': freq_bands},\n",
    "        n_jobs=N_CORES,\n",
    "        memory=cache_path\n",
    "    )\n",
    "\n",
    "    # each returns (n_epochs √ó n_features). Here n_features = 1 (the mu band power).\n",
    "    base_feat_L = fx.fit_transform(base_left)[:, 0]\n",
    "    act_feat_L  = fx.fit_transform(act_left)[:, 0]\n",
    "    base_feat_R = fx.fit_transform(base_right)[:, 0]\n",
    "    act_feat_R  = fx.fit_transform(act_right)[:, 0]\n",
    "\n",
    "    # --- 4) Compute ERD/ERS per side ---\n",
    "    erd_ers_L = (act_feat_L - base_feat_L) / base_feat_L\n",
    "    erd_ers_R = (act_feat_R - base_feat_R) / base_feat_R\n",
    "\n",
    "    # --- 5) Build Laterality Coefficient from left‚Äëvs‚Äëright CSP components ---\n",
    "    results = []\n",
    "    for i, ev in enumerate(events_list):\n",
    "        if ev == 'right':\n",
    "            # contralateral = left CSP; ipsilateral = right CSP\n",
    "            contra = erd_ers_L[i]\n",
    "            ipsi   = erd_ers_R[i]\n",
    "        elif ev == 'left':\n",
    "            # contralateral = right CSP; ipsilateral = left CSP\n",
    "            contra = erd_ers_R[i]\n",
    "            ipsi   = erd_ers_L[i]\n",
    "        else:\n",
    "            # skip unknown events\n",
    "            continue\n",
    "\n",
    "        # laterality coefficient\n",
    "        lc = np.nan\n",
    "        denom = (contra + ipsi)\n",
    "        if denom != 0:\n",
    "            lc = (contra - ipsi) / denom\n",
    "\n",
    "        results.append({'event': ev, 'LC': lc})\n",
    "\n",
    "    return pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "csv_path = 'laterality_results.csv'\n",
    "results = []\n",
    "\n",
    "# Check if the CSV file already exists\n",
    "file_exists = os.path.exists(csv_path)\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    subject_id = row['subject']\n",
    "    stage = row['stage']\n",
    "    split = row['split']\n",
    "    epochs = row['epochs']\n",
    "    \n",
    "    # Compute LC DataFrame\n",
    "    lc_df = calculate_batch_laterality_coefficients(epochs)\n",
    "    \n",
    "    # Add metadata\n",
    "    lc_df['subject'] = subject_id\n",
    "    lc_df['stage'] = stage\n",
    "    lc_df['split'] = split\n",
    "    \n",
    "    # Reorder columns\n",
    "    lc_df = lc_df[['subject', 'stage', 'split', 'event', 'LC']]\n",
    "    \n",
    "    # Append to CSV\n",
    "    lc_df.to_csv(csv_path, mode='a', index=False, header=not file_exists)\n",
    "    \n",
    "    # After first write, set file_exists to True\n",
    "    file_exists = True\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleep_stage_classification_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
